{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yasirkhan1811/us-accidents-data-analysis-2016-2023?scriptVersionId=143072914\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Complete Data Analysis of US Accidents (2016-2023)\n---\n---","metadata":{}},{"cell_type":"markdown","source":"\"This is a countrywide car accident dataset that covers 49 states of the USA. The accident data were collected from February 2016 to March 2023, using multiple APIs that provide streaming traffic incident (or event) data. These APIs broadcast traffic data captured by various entities, including the US and state departments of transportation, law enforcement agencies, traffic cameras, and traffic sensors within the road networks. The dataset currently contains approximately **7.7 million** accident records.\"\nThis Dataset can be accessed here: Sobhan Moosavi. (2023). <i>US Accidents (2016 - 2023)</i> [Data set]. Kaggle. https://doi.org/10.34740/KAGGLE/DS/199387","metadata":{}},{"cell_type":"markdown","source":"The primary goal of the project is to analyze and generate insights on the traffic accidents that took place in USA from Feb. 2016 to Mar. 2023. The first part of the analysis will examine countrywide accident events. In second part, the data will be filtered for a US city where most number of accidents have occurered, then the city data will be analyzed to produce valuable insights about accients in that city.\n\nThroughout the analysis, the following questions will be answered:\n\n**Countrywide Analysis:**\n\n1. What are the top 10 U.S. states with the highest number of accidents?\n2. What are the top 10 Cities with most number of accidents?\n3. What is the trend of accidents by year from 2016 to 2023?\n4. What are the average monthly accidents (2016-2023)?\n5. Which days of the week have a higher probability of accidents?\n6. What is the distribution of hourly accidents throughout the day? \n7. Are there specific hours of the day when accidents are more likely to occur?\n8. What are the most frequent words in the descriptions of severity 4 accidents?\n9. What are the top weather conditions that contribute to the accidents?\n10. What were the most common road features during the accidents?\n\n**Miami City Analysis:**\n\n1. Timeseries Analysis of the accidents in Miami city, analysis by year, month, day of the week, and hour of the day.\n2. Which Miami streets are the most vulnerable to accidents?\n3. Which streets of Miami mostly result in 3rd and 4th level accident severities?\n4. Which streets cause higher delay time?\n3. Present the distribution of Accidents on the Miami City map.\n\n**To uncover the hidden stories from our data and present them in beautiful visuals to answer the above questions, let's get Started**","metadata":{}},{"cell_type":"markdown","source":"## Required Libraries\n---","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-15T06:02:47.464638Z","iopub.execute_input":"2023-09-15T06:02:47.465027Z","iopub.status.idle":"2023-09-15T06:02:47.945297Z","shell.execute_reply.started":"2023-09-15T06:02:47.464995Z","shell.execute_reply":"2023-09-15T06:02:47.944022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\nimport matplotlib.ticker as ticker\nimport matplotlib.patches as mpatches\nimport matplotlib.patheffects as PathEffects\n%matplotlib inline\n\nimport seaborn as sns\nimport calendar\nimport plotly as pt\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom pylab import *\n\nimport plotly.graph_objects as go\nfrom nltk.corpus import stopwords\n\nimport geopandas as gpd\nimport geoplot\nfrom geopy.geocoders import Nominatim\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:02:47.947296Z","iopub.execute_input":"2023-09-15T06:02:47.947751Z","iopub.status.idle":"2023-09-15T06:02:59.473024Z","shell.execute_reply.started":"2023-09-15T06:02:47.947718Z","shell.execute_reply":"2023-09-15T06:02:59.471805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Import\n---\n\nIn the first place we are going to import the dataset using Pandas module.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/us-accidents/US_Accidents_March23.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:02:59.475182Z","iopub.execute_input":"2023-09-15T06:02:59.476473Z","iopub.status.idle":"2023-09-15T06:05:28.746296Z","shell.execute_reply.started":"2023-09-15T06:02:59.476419Z","shell.execute_reply":"2023-09-15T06:05:28.742957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Size of our Dataset:\", df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:05:28.750466Z","iopub.execute_input":"2023-09-15T06:05:28.751033Z","iopub.status.idle":"2023-09-15T06:05:28.761246Z","shell.execute_reply.started":"2023-09-15T06:05:28.750977Z","shell.execute_reply":"2023-09-15T06:05:28.759806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the Pandas display options to show all columns\npd.set_option('display.max_columns', None)\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:05:28.765561Z","iopub.execute_input":"2023-09-15T06:05:28.765986Z","iopub.status.idle":"2023-09-15T06:05:28.842016Z","shell.execute_reply.started":"2023-09-15T06:05:28.765937Z","shell.execute_reply":"2023-09-15T06:05:28.84037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleansing\n---\n\nThis dataset contains a large amount of information for analysis. However, some of the fields may be overly complex and not contribute significantly to our analysis. Before proceeding further, I plan to streamline the dataset by removing the following fields:\n\n1. 'Id' and 'Source': These fields do not provide substantial information for our analysis.\n\n2. 'End_Lat' and 'End_Lng': We already have the starting coordinates, making these fields redundant.\n\n3. 'Airport_Code': Since all the data pertains to the USA, specifying the nearest airport code is unnecessary.\n\n4. 'Country': As mentioned earlier, all the data is related to the USA, so this field does not add value.\n\n5. 'Weather_Timestamp': We have other weather-related fields that are more relevant.\n\n6. 'Civil_Twilight', 'Nautical_Twilight', and 'Astronomical_Twilight': These fields may not be directly relevant to our analysis.\n\n7. 'Timezone': This information can be derived from other relevant fields.\n\nBy removing these fields, we aim to simplify the dataset, making it more focused and efficient for our analysis.","metadata":{}},{"cell_type":"code","source":"# Specify the names of the columns to be dropped\ncolumns_to_drop = ['End_Lat', 'End_Lng', 'ID', 'Source', 'Airport_Code', 'Country', 'Weather_Timestamp', 'Turning_Loop',\n                   'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight', 'Timezone']\n\n# Use the drop() method to remove the specified columns\ndf.drop(columns=columns_to_drop, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:05:28.843859Z","iopub.execute_input":"2023-09-15T06:05:28.84438Z","iopub.status.idle":"2023-09-15T06:05:32.077497Z","shell.execute_reply.started":"2023-09-15T06:05:28.844345Z","shell.execute_reply":"2023-09-15T06:05:32.076372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Quick overview of the Data:**","metadata":{}},{"cell_type":"code","source":"from pprint import pprint\ndef sanity_check(df):\n    pprint('-'*70)\n    pprint('No. of Rows: {0[0]}        No. of Columns : {0[1]}'.format(df.shape))\n    pprint('-'*70)\n    data_profile = pd.DataFrame(df.dtypes.reset_index()).rename(columns = {'index' : 'Attribute',\n                                                                           0 : 'DataType'}).set_index('Attribute')\n    \n    data_profile = pd.concat([data_profile,df.isnull().sum()], axis=1).rename(columns = {0 : 'Missing Values'})\n    data_profile = pd.concat([data_profile,(df.isnull().mean()*100).round(2)], axis=1).rename(columns = {0 : 'Missing %'})\n    data_profile = pd.concat([data_profile,df.nunique()], axis=1).rename(columns = {0 : 'Unique Values'})\n    \n    pprint(data_profile)\n    pprint('-'*70)\n\nsanity_check(df)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:05:32.07999Z","iopub.execute_input":"2023-09-15T06:05:32.080697Z","iopub.status.idle":"2023-09-15T06:06:22.132721Z","shell.execute_reply.started":"2023-09-15T06:05:32.080649Z","shell.execute_reply":"2023-09-15T06:06:22.131265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our dataset is quite extensive, with over 7 million entries. Consequently, removing rows associated with columns containing less than 5% missing data won't significantly impact our analysis. Therefore, we can safely eliminate data with less than 5% missing values.","metadata":{}},{"cell_type":"code","source":"df.dropna(subset=['Visibility(mi)', 'Wind_Direction', 'Description', 'Humidity(%)', 'Weather_Condition', 'Temperature(F)',\n                  'Pressure(in)', 'Sunrise_Sunset', 'Street', 'Zipcode'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:06:22.134435Z","iopub.execute_input":"2023-09-15T06:06:22.135447Z","iopub.status.idle":"2023-09-15T06:06:31.29017Z","shell.execute_reply.started":"2023-09-15T06:06:22.135408Z","shell.execute_reply":"2023-09-15T06:06:31.288667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the columns, **Precipitation(in), Wind_Chill(F), and Wind_Speed(mph)**, the missing data is in high percentage, removing missing data from these columns would cause us to lose a lot of data (around 3 million records). Therefore, we are going to impute them with the mean values of those fields.","metadata":{}},{"cell_type":"code","source":"# Calculate the mean values for each column\nmean_1 = df['Precipitation(in)'].mean()\nmean_2 = df['Wind_Chill(F)'].mean()\nmean_3 = df['Wind_Speed(mph)'].mean()\n\n# Impute missing values in each column with their respective means\ndf['Precipitation(in)'].fillna(mean_1, inplace=True)\ndf['Wind_Chill(F)'].fillna(mean_2, inplace=True)\ndf['Wind_Speed(mph)'].fillna(mean_3, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:06:31.291942Z","iopub.execute_input":"2023-09-15T06:06:31.292469Z","iopub.status.idle":"2023-09-15T06:06:31.485342Z","shell.execute_reply.started":"2023-09-15T06:06:31.292421Z","shell.execute_reply":"2023-09-15T06:06:31.483973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's run the sanity check on the modified data.","metadata":{}},{"cell_type":"code","source":"sanity_check(df)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:06:31.487282Z","iopub.execute_input":"2023-09-15T06:06:31.487715Z","iopub.status.idle":"2023-09-15T06:07:17.647509Z","shell.execute_reply.started":"2023-09-15T06:06:31.487667Z","shell.execute_reply":"2023-09-15T06:07:17.646207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Remove duplicate rows**","metadata":{}},{"cell_type":"code","source":"print(\"Number of rows:\", len(df.index))\ndf.drop_duplicates(inplace=True)\nprint(\"Number of rows after dropping duplicates:\", len(df.index))","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:07:17.649217Z","iopub.execute_input":"2023-09-15T06:07:17.649732Z","iopub.status.idle":"2023-09-15T06:08:07.146542Z","shell.execute_reply.started":"2023-09-15T06:07:17.649685Z","shell.execute_reply":"2023-09-15T06:08:07.145256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring Accidents: A Deep Dive into Data Insights\n---","metadata":{}},{"cell_type":"markdown","source":"**Number of Accidents by State**","metadata":{}},{"cell_type":"code","source":"state_counts = df[\"State\"].value_counts()\nfig = go.Figure(data=go.Choropleth(locations=state_counts.index, z=state_counts.values.astype(float), \n                                   locationmode=\"USA-states\", colorscale=\"turbo\"))\nfig.update_layout(title_text=\"Number of Accidents by State\", geo_scope=\"usa\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:07.148563Z","iopub.execute_input":"2023-09-15T06:08:07.149372Z","iopub.status.idle":"2023-09-15T06:08:08.725454Z","shell.execute_reply.started":"2023-09-15T06:08:07.149322Z","shell.execute_reply":"2023-09-15T06:08:08.723985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Which are the top 10 U.S. states with the highest number of accidents?**","metadata":{}},{"cell_type":"code","source":"states = pd.DataFrame(state_counts).reset_index().sort_values('count', ascending=False)\nstates.rename(columns={'State':'state_code', 'count':'cases'}, inplace=True)\n\nus_states = {\n    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n    'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n    'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',\n    'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland', 'MA': 'Massachusetts',\n    'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana',\n    'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico',\n    'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',\n    'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont',\n    'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'\n}\n\n# Add a new column 'State_Name' based on 'State_Code'\nstates['state'] = states['state_code'].map(us_states)\n\n# Display the updated DataFrame\nstates.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:08.728865Z","iopub.execute_input":"2023-09-15T06:08:08.730178Z","iopub.status.idle":"2023-09-15T06:08:08.755097Z","shell.execute_reply.started":"2023-09-15T06:08:08.730096Z","shell.execute_reply":"2023-09-15T06:08:08.753896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (12,5), dpi = 80)\nsns.set_style('ticks')\n\ntop_10 = states[:10]\n\nsns.barplot(x=top_10['state'], y=top_10['cases'], palette='colorblind')\n\nplt.title(\"Top 10 states with the highest number of accidents\\n\", fontdict = {'fontsize':16, 'color':'MidnightBlue'})\nplt.ylabel(\"\\nNumber of Accidents\", fontdict = {'fontsize':12, 'color':'black'})\nplt.xticks(rotation=30)\nplt.xlabel(None)\n\ntotal_accidents = df.shape[0]\nfor p in ax.patches :\n    height = p.get_height()\n    ax.text(p.get_x() + p.get_width()/2,\n            height + 20000,\n            '{:.2f}%'.format(height/total_accidents*100),\n            ha = \"center\",\n            fontsize = 10, weight = 'bold', color='MidnightBlue')\n\n# Increase the font size of the axis tick labels\nsns.set(rc={'xtick.labelsize': 12, 'ytick.labelsize': 12})\n\n# Customize Y-axis tick labels to show real numbers\ndef format_func(value, _):\n    return f'{value:.0f}'  # Format as whole numbers\nax.yaxis.set_major_formatter(FuncFormatter(format_func))\n\nfor i in ['top', 'right']:\n    ax.spines[i].set_color('white')\n    ax.spines[i].set_linewidth(1.5)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:08.762843Z","iopub.execute_input":"2023-09-15T06:08:08.763664Z","iopub.status.idle":"2023-09-15T06:08:09.547889Z","shell.execute_reply.started":"2023-09-15T06:08:08.763622Z","shell.execute_reply":"2023-09-15T06:08:09.546658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see from the map and the bar chart, California has the highest number of accidents, followed by Florida and Texas.","metadata":{}},{"cell_type":"markdown","source":"**What are the top 10 Cities with most number of accidents?**","metadata":{}},{"cell_type":"code","source":"cities = pd.DataFrame(df[\"City\"].value_counts()).reset_index().sort_values(by='count',ascending=False)\ncities = cities.rename(columns={'City':'city','count':'cases'})","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:09.550165Z","iopub.execute_input":"2023-09-15T06:08:09.551086Z","iopub.status.idle":"2023-09-15T06:08:11.22855Z","shell.execute_reply.started":"2023-09-15T06:08:09.551037Z","shell.execute_reply":"2023-09-15T06:08:11.227088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (12,4), dpi = 80)\nsns.set_style('ticks')\n\nsns.barplot(x=cities[:10].city, y=cities[:10].cases, palette='colorblind')\nplt.title(\"Top 10 Cities with most number of accidents\\n\", fontdict = {'fontsize':16, 'color':'MidnightBlue'})\nplt.ylabel(\"\\nNumber of Accidents\", fontdict = {'fontsize':12, 'color':'black'})\nplt.xlabel(None)\nplt.xticks(rotation=30)\n\n# Increase the font size of the axis tick labels\nsns.set(rc={'xtick.labelsize': 12, 'ytick.labelsize': 12})\n\n# Customize Y-axis tick labels to show real numbers\ndef format_func(value, _):\n    return f'{value:.0f}'  # Format as whole numbers\nax.yaxis.set_major_formatter(FuncFormatter(format_func))\n\nfor i in ['top', 'right']:\n    ax.spines[i].set_color('white')\n    ax.spines[i].set_linewidth(1.5)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:11.230334Z","iopub.execute_input":"2023-09-15T06:08:11.230688Z","iopub.status.idle":"2023-09-15T06:08:11.672547Z","shell.execute_reply.started":"2023-09-15T06:08:11.230656Z","shell.execute_reply":"2023-09-15T06:08:11.67101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Time Series Analysis\n---","metadata":{}},{"cell_type":"code","source":"# convert the Start_Time and End_Time attributes to datetime\ndf[\"Start_Time\"] = pd.to_datetime(df[\"Start_Time\"], format=\"mixed\", errors='coerce', dayfirst=True)\ndf[\"End_Time\"] = pd.to_datetime(df[\"End_Time\"], format=\"mixed\", errors='coerce', dayfirst=True)\n\n# Extract year, month, weekday and day\ndf[\"Year\"] = df[\"Start_Time\"].dt.year\ndf[\"Month\"] = df[\"Start_Time\"].dt.month\ndf[\"Weekday\"] = df[\"Start_Time\"].dt.weekday\ndf[\"Day\"] = df[\"Start_Time\"].dt.day\ndf[\"Hour\"] = df[\"Start_Time\"].dt.hour","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:11.674334Z","iopub.execute_input":"2023-09-15T06:08:11.674807Z","iopub.status.idle":"2023-09-15T06:08:26.872149Z","shell.execute_reply.started":"2023-09-15T06:08:11.674762Z","shell.execute_reply":"2023-09-15T06:08:26.870905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**How do the accidents vary by year?**","metadata":{}},{"cell_type":"code","source":"year_df = pd.DataFrame(df['Year'].value_counts()).reset_index().sort_values(by='Year', ascending=True)\nyear = year_df.rename(columns={'Year':'year','count':'cases'})","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:26.873865Z","iopub.execute_input":"2023-09-15T06:08:26.874264Z","iopub.status.idle":"2023-09-15T06:08:26.934426Z","shell.execute_reply.started":"2023-09-15T06:08:26.874231Z","shell.execute_reply":"2023-09-15T06:08:26.932965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (8,5), dpi = 80)\nsns.set_style('ticks') # style must be one of white, dark, whitegrid, darkgrid, ticks \n\n# Determine the colors (as before)\ncolors = ['red' if val == max(year['cases']) else 'skyblue' if val == min(year['cases']) else 'lightgrey' for val in year['cases']]\n\nsns.barplot(x=year.year, y=year.cases, palette=colors)\nax.spines[('top')].set_visible(False)\nax.spines[('right')].set_visible(False)\nax.set_xlabel(None)\nax.set_ylabel(\"No. of Accidents\")\nax.set_title('Yearly Overview: Accidents Count and Percentage (2022-2023)\\n', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\n\n# Customize Y-axis tick labels to show real numbers\ndef format_func(value, _):\n    return f'{value:.0f}'  # Format as whole numbers\nax.yaxis.set_major_formatter(FuncFormatter(format_func))\n\nfor p in ax.patches :\n    height = p.get_height()\n    ax.text(p.get_x() + p.get_width()/2,\n            height + 20000,\n            '{:.2f}%'.format(height/total_accidents*100),\n            ha = \"center\",\n            fontsize = 10, weight='bold', color='MidnightBlue')\n\nfor i in ['top','right']:\n    side = ax.spines[i]\n    side.set_visible(False)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:26.93617Z","iopub.execute_input":"2023-09-15T06:08:26.936536Z","iopub.status.idle":"2023-09-15T06:08:27.305997Z","shell.execute_reply.started":"2023-09-15T06:08:26.936506Z","shell.execute_reply":"2023-09-15T06:08:27.304424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What are the average monthly accidents (2016-2023)?**","metadata":{}},{"cell_type":"code","source":"month_df = pd.DataFrame(df.Start_Time.dt.month.value_counts()).reset_index()\nmonth = month_df.rename(columns={'Start_Time':'month#','count':'cases'}).sort_values(by='month#', ascending=True)\n\n# adding month name as a column\nmonth_map = {1:'Jan' , 2:'Feb' , 3:'Mar' , 4:'Apr' , 5:'May' , 6:'Jun', 7:'Jul' , 8:'Aug', 9:'Sep',10:'Oct' , 11:'Nov' , 12:'Dec'}\nmonth['month_name'] = month['month#'].map(month_map)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:27.308334Z","iopub.execute_input":"2023-09-15T06:08:27.308848Z","iopub.status.idle":"2023-09-15T06:08:28.092759Z","shell.execute_reply.started":"2023-09-15T06:08:27.308799Z","shell.execute_reply":"2023-09-15T06:08:28.091685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (12,4), dpi = 80)\nsns.set_style('ticks')\n\n# Determine the colors (as before)\ncolors = ['red' if val == max(month['cases']) else 'skyblue' if val == min(month['cases']) else 'lightgrey' for val in month['cases']]\n\nsns.barplot(x=month.month_name, y=month.cases, palette=colors)\n\nax.set_title('Average Monthly Accidents (2022-2023)\\n', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\nax.set_ylabel(\"\\nNo. of Accidents\\n\", fontsize = 12)\nax.set_xlabel(None)\n\n# Customize Y-axis tick labels to show real numbers\ndef format_func(value, _):\n    return f'{value:.0f}'  # Format as whole numbers\nax.yaxis.set_major_formatter(FuncFormatter(format_func))\n\nfor p in ax.patches :\n    height = p.get_height()\n    ax.text(p.get_x() + p.get_width()/2,\n            height + 15000,\n            '{:.2f}%'.format(height/total_accidents*100),\n            ha = \"center\",\n            fontsize = 10, weight='bold', color='MidnightBlue')\n\nfor i in ['top', 'right']:\n    side = ax.spines[i]\n    side.set_visible(False)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:28.094201Z","iopub.execute_input":"2023-09-15T06:08:28.095523Z","iopub.status.idle":"2023-09-15T06:08:28.46248Z","shell.execute_reply.started":"2023-09-15T06:08:28.09548Z","shell.execute_reply":"2023-09-15T06:08:28.460862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Which days of the week have higher probability of accidents?**","metadata":{}},{"cell_type":"code","source":"dow = pd.DataFrame(df['Start_Time'].dt.dayofweek.value_counts()).reset_index()\ndow = dow.rename(columns={'Start_Time':'day_of_week', 'count':'cases'}).sort_values(by='day_of_week')\nday_map = {0:'Monday' , 1:'Tuesday' , 2:'Wednesday' , 3:\"Thursday\" , 4:'Friday' , 5:\"Saturday\" , 6:'Sunday'}   \ndow['weekday'] = dow['day_of_week'].map(day_map)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:28.467207Z","iopub.execute_input":"2023-09-15T06:08:28.467651Z","iopub.status.idle":"2023-09-15T06:08:29.318159Z","shell.execute_reply.started":"2023-09-15T06:08:28.467613Z","shell.execute_reply":"2023-09-15T06:08:29.316992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (8,4), dpi = 80)\nsns.set_style('ticks') \n\nax=sns.barplot(y=dow.cases, x=dow.weekday, palette='pastel')\nplt.title('Number of Accidents by Day of the Week\\n', size=16, color='MidnightBlue')\nplt.ylabel('\\nAccident Cases', fontsize=12)\nplt.xlabel('\\nDay of the Week', fontsize=12)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\n\ntotal = df.shape[0]\nfor i in ax.patches:\n    ax.text(i.get_x()+0.1, i.get_height()-55000,\n    str(round((i.get_height()/total)*100, 2))+'%',\n    va = \"center\", fontsize=10, weight='bold', color='MidnightBlue')\n\nfor i in ['top', 'right']:\n    side = ax.spines[i]\n    side.set_visible(False)\n\n# Customize Y-axis tick labels to show real numbers\ndef format_func(value, _):\n    return f'{value:.0f}'  # Format as whole numbers\nax.yaxis.set_major_formatter(FuncFormatter(format_func))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:29.319689Z","iopub.execute_input":"2023-09-15T06:08:29.320235Z","iopub.status.idle":"2023-09-15T06:08:29.648557Z","shell.execute_reply.started":"2023-09-15T06:08:29.320192Z","shell.execute_reply":"2023-09-15T06:08:29.647592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the chart above, it's evident that weekdays experience significantly more accidents compared to weekends, with weekend accident frequencies being at least 2/3 times lower. This trend may be attributed to the reduced volume of vehicles on the road during weekends.","metadata":{}},{"cell_type":"markdown","source":"**What is the distribution of accidents throughout the day, and are there specific hours when accidents are more likely to occur?**","metadata":{}},{"cell_type":"code","source":"hour_of_day = pd.DataFrame(df['Hour'].value_counts()).reset_index().rename(columns={'Hour':'hour','count':'cases'})\nhour_of_day.sort_values(by='hour', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:29.650064Z","iopub.execute_input":"2023-09-15T06:08:29.650786Z","iopub.status.idle":"2023-09-15T06:08:29.720197Z","shell.execute_reply.started":"2023-09-15T06:08:29.650746Z","shell.execute_reply":"2023-09-15T06:08:29.718347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 4), dpi=80)\nsns.set_style('ticks')\n\ncolors = []\nfor x in hour_of_day['cases']:\n    if int(hour_of_day[hour_of_day['cases'] == x]['hour']) <= 11:\n        if x == max(list(hour_of_day['cases'])[:12]):\n            colors.append('red')\n        else:\n            colors.append('skyblue')\n    else:\n        if x == max(list(hour_of_day['cases'])[12:]):\n            colors.append('red')\n        else:\n            colors.append('lightgrey') \n\n# Create a bar plot of 'hourly_accident_rate'\nsns.barplot(x=hour_of_day.hour, y=hour_of_day.cases, palette=colors)\n\nplt.title('Hourly Accident Rate\\n', size=16, color='MidnightBlue')\nplt.ylabel('\\nAccident Cases', fontsize=12)\nplt.xlabel('\\nTime of Day', fontsize=12)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\n\nfor i in ['top', 'right']:\n    side = ax.spines[i]\n    side.set_visible(False)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:29.722266Z","iopub.execute_input":"2023-09-15T06:08:29.722789Z","iopub.status.idle":"2023-09-15T06:08:30.225114Z","shell.execute_reply.started":"2023-09-15T06:08:29.72274Z","shell.execute_reply":"2023-09-15T06:08:30.22381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The early morning hours (around 7 AM) and the evening hours (around 4 PM) are associated with the highest number of accidents, with each time experienced more than **50,000** accidents on average.","metadata":{}},{"cell_type":"markdown","source":"## Accident Severity Analysis\n---","metadata":{}},{"cell_type":"markdown","source":"**What are the most frequent words in the descriptions of severity 4 accidents?**\n\nWe will find and list the most common words in the \"description\" column of accidents that have a severity level of 4 using some stopwords from the english language.","metadata":{}},{"cell_type":"code","source":"stop = stopwords.words(\"english\") + [\"-\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:30.226581Z","iopub.execute_input":"2023-09-15T06:08:30.226951Z","iopub.status.idle":"2023-09-15T06:08:30.238256Z","shell.execute_reply.started":"2023-09-15T06:08:30.22692Z","shell.execute_reply":"2023-09-15T06:08:30.236934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Here is the complete breakdown of the above code:**\n\n- stopwords is an NLTK module that provides access to stopwords for various languages, including English.\n- `stopwords.words(\"english\")` retrieves the list of English stopwords from NLTK's predefined stopwords corpus for the English language.\n- `+[\"-\"]` After obtaining the list of English stopwords, the code appends a custom word, \"-\" (a hyphen), to the list.\n\nThe final result is a Python list (stop) that contains both the NLTK English stopwords and the custom word \"-\", combined into a single list. This list can be used for text processing tasks such as text cleaning, tokenization, and removing stopwords from text data. The \"-\" symbol has been included in this list to treat it as a stopword, which means it can be easily removed or filtered out when processing text data.","metadata":{}},{"cell_type":"code","source":"description_s4 = df[df[\"Severity\"] == 4][\"Description\"] # filter the data\n# Split the description\ndf_words = description_s4.str.lower().str.split(expand=True).stack()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:30.240327Z","iopub.execute_input":"2023-09-15T06:08:30.241241Z","iopub.status.idle":"2023-09-15T06:08:34.369621Z","shell.execute_reply.started":"2023-09-15T06:08:30.241165Z","shell.execute_reply":"2023-09-15T06:08:34.368248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Explanation of the above code:**\n\n- `.str.lower()`: it converts all the text in the description to lowercase.\n- `.str.split(expand=True)`: it splits the text in each row of the description into individual words.\n- The `(expand=True)` parameter ensures that the result is returned as a DataFrame with one word per column. Each row in the resulting DataFrame will contain the words extracted from the corresponding description.\n- `.stack()`: after splitting the text into words and creating a DataFrame with one word per column, this method \"stacks\" the DataFrame, effectively converting it back into a Series.\n- The result is a Series with a multi-level index, where the first level corresponds to the original index of the descriptions in description_s4, and the second level contains the individual words from each description.","metadata":{}},{"cell_type":"code","source":"# If the word is not in the stopwords list\ncounts = df_words[~df_words.isin(stop)].value_counts()[:10]","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:34.371379Z","iopub.execute_input":"2023-09-15T06:08:34.371781Z","iopub.status.idle":"2023-09-15T06:08:35.325662Z","shell.execute_reply.started":"2023-09-15T06:08:34.371743Z","shell.execute_reply":"2023-09-15T06:08:35.32451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Code explanation:**\n\n- This code is used to count the occurrences of words in `df_words` while excluding words that are in a list of stopwords `stop`","metadata":{}},{"cell_type":"code","source":"# visualize the frequencies of the top 10 words in the description\nfig, ax = plt.subplots(figsize=(8, 5), dpi=80)\nsns.set_style('ticks')\nsns.barplot(x=counts.values, y=counts.index, orient=\"h\", palette = \"cividis\")\n\nax.set_title(\"Top 10 words in the description of Severity 4 Accidents\\n\", fontsize=16, color='MidnightBlue')\nax.set_xlabel(\"\\nFrequency of each word\\n\")\nax.set_ylabel(None)\n\nfor i in ['top', 'right']:\n    side = ax.spines[i]\n    side.set_visible(False)\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:35.327544Z","iopub.execute_input":"2023-09-15T06:08:35.328176Z","iopub.status.idle":"2023-09-15T06:08:35.672343Z","shell.execute_reply.started":"2023-09-15T06:08:35.328115Z","shell.execute_reply":"2023-09-15T06:08:35.670912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the most used word in the description is closed. Subsequent words are accident, due and road.","metadata":{}},{"cell_type":"code","source":"s4_by_yr = df[df['Severity'] == 4][['Severity','Year']].groupby('Year').agg({'Severity': 'count'}).mean().round(0)\n\nfig, (ax1,ax2) = plt.subplots(1,2,figsize=(20,6))\n\n# Calculate the percentage of each severity level\nseverity = df['Severity'].value_counts(normalize=True).round(2) * 100\nseverity.plot.pie(autopct = '%1.1f%%' , ax=ax1, colors =sns.color_palette(palette='Pastel1'),\n                                        pctdistance = 0.8, explode = [.03,.03,.03,.03], \n                                        textprops = {'fontsize' : 12 , 'color' : 'DarkSlateBlue'},\n                                        labels=['Severity 2','Severity 3' , 'Severity 4' , 'Severity 1'])\n\nax1.set_title(\"Percent Breakdown of Accident Severity\", fontdict = {'fontsize':16 , 'color':'MidnightBlue'} )\nax1.set_ylabel(None)\n\ns = sns.countplot(data=df[['Severity','Year']] , x = 'Year' , hue='Severity' , ax=ax2, palette = 'rainbow', edgecolor='black')\n\nax2.axhline(s4_by_yr[0], color='Blue', linewidth=1, linestyle='dashdot')\nax2.annotate(f\"Average # of Severity 4 Accidents: {s4_by_yr[0]}\",\n            va = 'center', ha='center',\n            color='#4a4a4a',\n            bbox=dict(boxstyle='round', pad=0.4, facecolor='Wheat', linewidth=0), xy=(-0.5,80000))\n\nax2.set_title(\"Trend of Severity Level by Year\", fontdict = {'fontsize':16 , 'color':'MidnightBlue'} )\nax2.set_ylabel(\"\\nNo. of Accidents\", fontdict = {'fontsize':16 , 'color':'MidnightBlue'} )\nax2.set_xlabel(None)\n\nfor i in ['top', 'right']:\n    side = ax2.spines[i]\n    side.set_visible(False)\n\n# sns.despine(left=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:35.673807Z","iopub.execute_input":"2023-09-15T06:08:35.67425Z","iopub.status.idle":"2023-09-15T06:08:38.110995Z","shell.execute_reply.started":"2023-09-15T06:08:35.674218Z","shell.execute_reply":"2023-09-15T06:08:38.109723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The charts above illustrate a significant trend: approximately 80% of accidents lead to **Severity 02** injuries, it's increasing magnitude each year. Despite constituting only 20% of total accidents, **Severity 3 and 4** injuries remain a serious concern due to their proximity to fatal outcomes, emphasizing the need for continued safety measures.","metadata":{}},{"cell_type":"markdown","source":"## Weather Condition Analysis\n---","metadata":{}},{"cell_type":"markdown","source":"**What are the top weather conditions that contribute to the accidents?**\n\nIf we analyze the weather conditions, we can see that there are lots of them, so it's better to reduce the number of unique conditions.","metadata":{}},{"cell_type":"code","source":"print(\"No. of Weather Conditions:\", len(df[\"Weather_Condition\"].unique()))\n\n# To view the complete list of 142 weather descriptions, run the following code\nprint(\"\\nList of unique weather conditions:\", list(df[\"Weather_Condition\"].unique()))","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:38.11241Z","iopub.execute_input":"2023-09-15T06:08:38.112893Z","iopub.status.idle":"2023-09-15T06:08:39.431687Z","shell.execute_reply.started":"2023-09-15T06:08:38.11285Z","shell.execute_reply":"2023-09-15T06:08:39.430476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To do so, we are going to replace these 142 unique conditions with more generic and broad contributing weather descriptions.","metadata":{}},{"cell_type":"code","source":"df.loc[df[\"Weather_Condition\"].str.contains(\"Thunder|T-Storm\", na=False), \"Weather_Condition\"] = \"Thunderstorm\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Snow|Sleet|Wintry\", na=False), \"Weather_Condition\"] = \"Snow\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Rain|Drizzle|Shower\", na=False), \"Weather_Condition\"] = \"Rain\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Wind|Squalls\", na=False), \"Weather_Condition\"] = \"Windy\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Hail|Pellets\", na=False), \"Weather_Condition\"] = \"Hail\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Fair\", na=False), \"Weather_Condition\"] = \"Clear\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Cloud|Overcast\", na=False), \"Weather_Condition\"] = \"Cloudy\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Mist|Haze|Fog\", na=False), \"Weather_Condition\"] = \"Fog\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Sand|Dust\", na=False), \"Weather_Condition\"] = \"Sand\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Smoke|Volcanic Ash\", na=False), \"Weather_Condition\"] = \"Smoke\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"N/A Precipitation\", na=False), \"Weather_Condition\"] = np.nan","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:08:39.433433Z","iopub.execute_input":"2023-09-15T06:08:39.433805Z","iopub.status.idle":"2023-09-15T06:09:43.352518Z","shell.execute_reply.started":"2023-09-15T06:08:39.433772Z","shell.execute_reply":"2023-09-15T06:09:43.351172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Code Explanation:**\n\n- `X[\"Weather_Condition\"]` selects the Weather_Condition column\n- `.str.contains(\"Thunder|T-Storm\", na=False), \"Weather_Condition\"` uses the `.str.contains()` method to look for the Thunder or T-Storm condition in the column\n- The na=False argument is used to treat missing values (NaN) as False, meaning that if a row has a missing value in the column, it won't be considered a match.\n- `X.loc[...]`: is responsible for selecting the rows that meet the specified condition above. It uses boolean indexing to filter the DataFrame\n- The code essentially assigns the value \"Thunderstorm\" to the \"Weather_Condition\" column in the rows, where the condition `.str.contains(\"Thunder|T-Storm\", na=False), \"Weather_Condition\"` is met.","metadata":{}},{"cell_type":"code","source":"wc = pd.DataFrame(df['Weather_Condition'].value_counts()).reset_index().sort_values(by='count', ascending=False)\nwc.rename(columns={'Weather_Condition':'weather_condition', 'count':'frequency'}, inplace=True)\n# wc stands for weather condition","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:09:43.35462Z","iopub.execute_input":"2023-09-15T06:09:43.355008Z","iopub.status.idle":"2023-09-15T06:09:44.465499Z","shell.execute_reply.started":"2023-09-15T06:09:43.354974Z","shell.execute_reply":"2023-09-15T06:09:44.464344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a figure and axis\nfig, ax = plt.subplots(figsize=(6, 4))\nsns.set_style('ticks')\nsns.barplot(x='frequency', y='weather_condition', data=wc, palette='cividis', orient='h')\n\n# Add labels and title\nax.set_xlabel('\\nFrequency')\nax.set_ylabel('\\nWeather Condition')\nax.set_title('\\nTop Weather Conditions Contributing to Accidents\\n', fontsize=16, color='MidnightBlue')\nplt.xticks(rotation=0)  # Adjust the rotation angle of x-axis labels\n\n# Increase the font size of the axis tick labels\nsns.set(rc={'xtick.labelsize': 10, 'ytick.labelsize': 10})\n\n# Remove top and right spines\nfor i in ['top', 'right']:\n    ax.spines[i].set_visible(False)\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:09:44.467264Z","iopub.execute_input":"2023-09-15T06:09:44.467592Z","iopub.status.idle":"2023-09-15T06:09:44.820159Z","shell.execute_reply.started":"2023-09-15T06:09:44.467563Z","shell.execute_reply":"2023-09-15T06:09:44.818704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**45%** of the accidents have occured on clear days. Other top weather conditions include: Cloudy, Rain, Fog, and Snow.","metadata":{}},{"cell_type":"markdown","source":"## Road Features Analysis\n---\n\n**What were the most common road features during the accidents?**","metadata":{}},{"cell_type":"code","source":"road_features = [\"Amenity\", \"Bump\", \"Crossing\", \"Give_Way\", \"Junction\", \"No_Exit\", \"Railway\", \"Roundabout\", \"Station\", \"Stop\",\n                 \"Traffic_Calming\", \"Traffic_Signal\"]\n\ndata = df[road_features].sum().sort_values(ascending=False)\n\nfig, ax = plt.subplots(figsize=(6, 4))\nsns.barplot(x=data.values, y=data.index, orient=\"h\", palette='cividis')\nplt.title(\"Most frequent road features\\n\", fontsize=16, color='MidnightBlue')\nplt.xlabel(\"\\nFrequency\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:09:44.82209Z","iopub.execute_input":"2023-09-15T06:09:44.822901Z","iopub.status.idle":"2023-09-15T06:09:45.368456Z","shell.execute_reply.started":"2023-09-15T06:09:44.822853Z","shell.execute_reply":"2023-09-15T06:09:45.367195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, most of the accidents occured near a traffic signal, expecially where a junction or a crossing was present. The fourth most common road feature, instead, was the presence of a nearby station, probably because of the high presence of vehicles.","metadata":{}},{"cell_type":"markdown","source":"## Analysis of Accidents in Miami City\n---","metadata":{}},{"cell_type":"markdown","source":"Since, Miami tops the list where most number of accidents have taken place from 2016 to 2023. Let's explore the time series data of the accidents in this city and finally we will make a map visual of the city to see which streets are the most vulnerable to accidents in Miami.","metadata":{}},{"cell_type":"code","source":"# filter the dataframe to view data related to Miami only\nmiami = df[df['City'] == 'Miami']\n\nyear = miami['Year'].value_counts()\nmonth = miami['Month'].value_counts().sort_index()\n\nmonth_map = {1:'Jan' , 2:'Feb' , 3:'Mar' , 4:'Apr' , 5:'May' , 6:'Jun', 7:'Jul' , 8:'Aug', 9:'Sep',10:'Oct' , 11:'Nov' , 12:'Dec'}\n\nhour = miami['Hour'].value_counts().sort_index()\nhour_severity = miami[['Hour' , 'Severity']].groupby('Hour').agg({'Hour':'count', 'Severity' : 'mean'})\n\ndaily_accidents = miami['Weekday'].value_counts().sort_index()\nday_map = {0:'Monday' , 1:'Tuesday' , 2:'Wednesday' , 3:\"Thursday\" , 4:'Friday' , 5:\"Saturday\" , 6:'Sunday'}\nyear_map = {x:x for x in year.index}\nhour_map = {x:x for x in hour.index}\n\nlight_palette = sns.color_palette(palette='pastel')","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:09:45.370113Z","iopub.execute_input":"2023-09-15T06:09:45.370904Z","iopub.status.idle":"2023-09-15T06:09:46.759243Z","shell.execute_reply.started":"2023-09-15T06:09:45.370867Z","shell.execute_reply":"2023-09-15T06:09:46.758013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Time Series Analysis of the Accidents in Miami City**\n\nSince we are going to draw time series plots, by year, month, weekday, and hour, it's better to visualize these charts in a single window for comprehensive view.","metadata":{}},{"cell_type":"code","source":"fig,([ax1,ax2],[ax3,ax4]) = plt.subplots(2,2,figsize=(16,9))\n\ndef plot_dist(kind, text, axis, LightCoral, skyblue):\n    '''\n    Reusable function to plot distribution based on input time criteria\n    Usage : plot_dist(kind, text, axis, red , green) - all params mandatory\n        kind : 'd' for day, 'm' for month , 'y' for year, 'h' for hour\n        red  : list of item to be rendered red (max)\n        skyblue : list of item to be rendered skyblue (min)\n        text : Text to be shownn as part of the title\n        axis : Axis to plot on\n    '''\n    if kind == 'd':\n        tot, ser, map = 7, daily_accidents, day_map\n    elif kind == 'm':\n        tot, ser, map = 12, month ,  month_map\n    elif kind == 'y':\n        tot, ser, map = 8, year ,  year_map\n    elif kind == 'h':\n        tot, ser, map = 24, hour ,  hour_map\n    \n    day_color_map = ['AliceBlue' for _ in range(tot)]\n    for l in LightCoral:\n        day_color_map[l] = 'LightCoral' \n    for s in skyblue:\n        day_color_map[s] = 'skyblue' \n    \n    sns.barplot(x=ser.index.map(map) , y=ser, ax = axis, palette = day_color_map)\n    axis.set_xlabel(None)\n    axis.set_ylabel(None)\n    axis.set_title(f'Accidents by {text}', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\n    axis.grid(axis='y', linestyle='-', alpha=0.4) \n    \nplt.subplots_adjust(wspace=0.2 , hspace = 0.4)\nplt.suptitle(\"Timeseries Analysis of Accidents in Miami\" , fontsize = 18 , color=\"MidnightBlue\")\n\nplot_dist('d' ,\"Days of the Week\", ax3,[0, 1, 2, 3, 4],[])\nplot_dist('y' ,\"Year\", ax1,[5,6],[])\nplot_dist('m' ,\"Month\", ax2, [0, 10, 11],[])\nplot_dist('h' ,\"Hour\", ax4,LightCoral=[13,14,15,16,17],skyblue=[])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:09:46.760622Z","iopub.execute_input":"2023-09-15T06:09:46.760987Z","iopub.status.idle":"2023-09-15T06:09:48.36697Z","shell.execute_reply.started":"2023-09-15T06:09:46.760954Z","shell.execute_reply":"2023-09-15T06:09:48.365549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What are the most accident-prone streets in Miami?**","metadata":{}},{"cell_type":"code","source":"top_st = miami['Street'].value_counts().sort_values(ascending=False).head(10).index.tolist()\nseverity_top_st = miami[miami['Street'].isin(top_st)][['Street' , 'Severity']].groupby('Street').mean()\n\n# add a delay_time column to the miami df\ndiff = miami['End_Time'] - miami['Start_Time']\nmiami['DelayTime'] = round(diff.dt.seconds/3600,1)\ntop_st_delay = miami[miami['Street'].isin(top_st)][['Street' , 'DelayTime']] .groupby('Street').mean()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:09:48.368542Z","iopub.execute_input":"2023-09-15T06:09:48.36891Z","iopub.status.idle":"2023-09-15T06:09:48.530744Z","shell.execute_reply.started":"2023-09-15T06:09:48.368878Z","shell.execute_reply":"2023-09-15T06:09:48.529463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax,ax1,ax2) = plt.subplots(3,1,figsize=(16,10), sharex=True)\n# fig.subplots_adjust(hspace=0)\n\nsns.countplot(data = miami[miami['Street'].isin(top_st)][['Street','Severity']],\n              x='Street',ax=ax2, palette='Pastel2')\n\nplt.xticks(rotation=30)\n\nax1.plot(severity_top_st, color='CornFlowerBlue', label='Severity',linewidth=3, linestyle='solid', \n         marker='.',markersize=18, markerfacecolor='w',markeredgecolor='b',markeredgewidth='2')","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:09:48.534375Z","iopub.execute_input":"2023-09-15T06:09:48.5348Z","iopub.status.idle":"2023-09-15T06:09:49.480506Z","shell.execute_reply.started":"2023-09-15T06:09:48.534766Z","shell.execute_reply":"2023-09-15T06:09:49.479313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax.plot(top_st_delay, color='LightCoral', label='Average Delay Time',linewidth=3, linestyle='solid',marker='*',\n        markersize=18, markerfacecolor='w',markeredgecolor='b',markeredgewidth='2')\n\nax.spines[('top')].set_visible(False)\nax.spines[('right')].set_visible(False)\nax1.spines[('right')].set_visible(False)\nax2.spines[('right')].set_visible(False)\nax2.set_xlabel(\"Miami Streets\", fontdict = {'fontsize':14 , 'color':'Teal'} )\nax2.set_ylabel(\"No. of Accidents\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'})\nax1.set_ylabel(\"Severity of Accidents\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'})\nax.set_ylabel(\"Avg. Delay Times (Hours)\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'})\nax.set_title('Accidents on Top Miami Streets, Severity and Delay', fontdict = {'fontsize':16 , \n                                                                               'color':'MidnightBlue'})\nax1.legend(loc=(0.01,0.8))\nax.legend(loc=(0.01,0.8))\nax.grid(axis='x', linestyle='-', alpha=0.4) \nax1.grid(axis='x', linestyle='-', alpha=0.4) \nax2.grid(axis='x', linestyle='-', alpha=0.4) \n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:09:49.482024Z","iopub.execute_input":"2023-09-15T06:09:49.482424Z","iopub.status.idle":"2023-09-15T06:09:49.505519Z","shell.execute_reply.started":"2023-09-15T06:09:49.482391Z","shell.execute_reply":"2023-09-15T06:09:49.504527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Street View Analysis on Miami Map\n---","metadata":{}},{"cell_type":"code","source":"import plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode,iplot,plot\ninit_notebook_mode(connected=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:09:49.512151Z","iopub.execute_input":"2023-09-15T06:09:49.512731Z","iopub.status.idle":"2023-09-15T06:09:49.521598Z","shell.execute_reply.started":"2023-09-15T06:09:49.512697Z","shell.execute_reply":"2023-09-15T06:09:49.520404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.density_mapbox(miami, lat='Start_Lat', lon='Start_Lng', z='Severity', hover_name='Street', radius=5,\n                        center=dict(lat=miami['Start_Lat'].median(), lon=miami['Start_Lng'].median()), zoom=12,\n                        mapbox_style=\"open-street-map\", height=900)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T06:09:49.523199Z","iopub.execute_input":"2023-09-15T06:09:49.523662Z","iopub.status.idle":"2023-09-15T06:09:52.549056Z","shell.execute_reply.started":"2023-09-15T06:09:49.523621Z","shell.execute_reply":"2023-09-15T06:09:52.548167Z"},"trusted":true},"execution_count":null,"outputs":[]}]}